[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Numerical Methods in Applied Mathematics, with Python",
    "section": "",
    "text": "Table of Contents\nWelcome to Numerical Methods in Applied Mathematics, with Python!\nIn this course, you’ll explore Python programming through interactive lessons. Each week includes examples and a link to open the lesson directly in Google Colab. If you choose, you can also download the .ipynb files and work on them locally.",
    "crumbs": [
      "Table of Contents"
    ]
  },
  {
    "objectID": "index.html#table-of-contents",
    "href": "index.html#table-of-contents",
    "title": "Numerical Methods in Applied Mathematics, with Python",
    "section": "",
    "text": "Preface\nModule 1\n\nWeek 1\nWeek 2\n\nModule 2\n\nWeek 3\nWeek 4\nWeek 5\n\nModule 3\n\nWeek 6\nWeek 7\n\nModule 4",
    "crumbs": [
      "Table of Contents"
    ]
  },
  {
    "objectID": "preface.html",
    "href": "preface.html",
    "title": "Preface - Ready to Start?",
    "section": "",
    "text": "To The Student\nThis book is a modified version of Eric Sullivan’s Numerical Methods and is also an Open Education Resource with the same license. Although the source material was not readily available, I will be modifying the original online book for the purposes of this course.\nThe prerequisites for this material include a firm understanding of single and multivariable variable calculus, a good understanding of the basics of linear algebra, a good understanding of the basics of differential equations.",
    "crumbs": [
      "Preface - Ready to Start?"
    ]
  },
  {
    "objectID": "preface.html#to-the-student",
    "href": "preface.html#to-the-student",
    "title": "Preface - Ready to Start?",
    "section": "",
    "text": "The Inquiry-Based Approach\nThe material in this book is meant to make you think, build, construct, fail, struggle, and ultimately succeed in learning numerical methods.\nSetting The Stage\nLet’s start the book off right away with a problem designed for groups, discussion, and critical thinking. This problem is inspired by Dana Ernst’s first day IBL activity titled: Setting the Stage.\n\nGet in groups of size 3-4.\nGroup members should introduce themselves.\nFor each of the questions that follow I will ask you to:\n\nThink about a possible answer on your own\nDiscuss your answers with the rest of the group\nShare a summary of each group’s discussion\n\n\nQuestions:\n\nWhat are the goals of a university education?\nHow does a person learn something new?\nWhat do you reasonably expect to remember from your courses in 20 years?\nWhat is the value of making mistakes in the learning process?\nHow do we create a safe environment where risk taking is encouraged and productive failure is valued?\n\nThis material is written with an Inquiry-Based Learning (IBL) flavor. In that sense, this document could be used as a stand-alone set of materials for the course but these notes are not a traditional textbook containing all of the expected theorems, proofs, code, examples, and exposition. You are encouraged to work through problems and homework, present your findings, and work together when appropriate. You will find that this document contains collections of problems with only minimal interweaving exposition.\nIt is expected that you do every one of the participation and homework problems and then only use other more traditional texts (or Google) as a backup when you are completely stuck. This is not the only set of material for the course. Your brain, your peers, and the books linked in the next section are your best resources when you are stuck.\nYou have the following jobs as a student in this class:\n\nMake Mistakes! More accurately, don’t be afraid to make mistakes. You should write code, work problems, and prove theorems then be completely unafraid to scrap what you’ve done and redo it from scratch. Learning this material is most definitely a non-linear path.\nCollaborate! You should collaborate with your peers, making sure you write your own solutions and noting who you collaborate with. The internet (or ChatGPT) is not a collaborator. Use of the internet to help solve these problems robs you of the most important part of this class; the chance for original thought.\nEnjoy! Part of the fun of IBL is that you get to experience what it is like to think like a true mathematician / scientist. It takes hard work but ultimately this should be fun!\n\n\nOnline Texts and Other Resources\nIf you are looking for online textbooks for numerical methods or numerical analysis, I can point you to a few. Some of the following online resources may be a good place to help you when you’re stuck but they will definitely say things a bit differently. Use these resources wisely.\n\nTea Time Numerical Analysis\nHolistic Numerical Methods - The Holistic Numerical Methods book is probably the most complete free reference that I’ve found on the web. This should be your source to look up deeper explanations of problems, algorithms, and code.",
    "crumbs": [
      "Preface - Ready to Start?"
    ]
  },
  {
    "objectID": "module_one.html",
    "href": "module_one.html",
    "title": "Module 1 - What is Numerical Analysis?",
    "section": "",
    "text": "Intro to Numerical Analysis\nThe field of Numerical Analysis is really the study of how to take mathematical problems and perform them efficiently and accurately on a computer. While the field of numerical analysis is quite powerful and wide-reaching, there are some mathematical problems where numerical analysis doesn’t make much sense (e.g. finding an algebraic derivative of a function, proving a theorem, uncovering a pattern in a sequence). However, for many problems a numerical method that gives an approximate answer is both more efficient and more versatile than any analytic technique. Let’s look at several examples. You can also watch a short introduction video here: https://youtu.be/yH0zhca0hbs\nExample from Algebra:\nSolve the equation \\(\\ln(x)=\\sin(x)\\) for \\(x\\) in the interval \\(x \\in (0,\\pi)\\). Stop and think about all of the algebra that you ever learned. You’ll quickly realize that there are no by-hand techniques that can solve this problem! A numerical approximation, however, is not so hard to come by.\nExample from Calculus:\nWhat if we want to evaluate the following integral?\n\\[\n\\int\\limits^{\\pi}_{0} \\sin(x^2) \\;dx\n\\]\nAgain, trying to use any of the possible techniques for using the Fundamental Theorem of Calculus, and hence finding an antiderivative, on the function \\(\\sin(x^2)\\) is completely hopeless. Substitution, integration by parts, and all of the other techniques that you know will all fail. Again, a numerical approximation is not so difficult and is very fast! By the way, this integral (called the Fresnel Sine Integral) actually shows up naturally in the field of optics and electromagnetism, so it is not just some arbitrary integral that I cooked up just for fun.\nExample from Differential Equations:\nSay we needed to solve the differential equation \\(\\frac{dy}{dt} = \\sin(y^2) + t\\). The nonlinear nature of the problem precludes us from using most of the typical techniques (e.g. separation of variables, undetermined coefficients, Laplace Transforms, etc). However, computational methods that result in a plot of an approximate solution can be made very quickly and likely give enough of a solution to be usable.\nExample from Linear Algebra:\nYou have probably never row reduced a matrix larger than \\(3 \\times 3\\) or perhaps \\(4 \\times 4\\) by hand. Instead, you often turn to technology to do the row reduction for you. You would be surprised to find that the standard row reduction algorithm (RREF) that you do by hand is not what a computer uses. Instead, there are efficient algorithms to do the basic operations of linear algebra (e.g. Gaussian elimination, matrix factorization, or eigenvalue decomposition)\nIn this chapter we will discuss some of the basic underlying ideas in Numerical Analysis, and the essence of the above quote from Nick Trefethen will be part of the focus of this chapter. Particularly, we need to know how a computer stores numbers and when that storage can get us into trouble. On a more mathematical side, we offer a brief review of the Taylor Series from Calculus at the end of this chapter. The Taylor Series underpins many of our approximation methods in this class. Finally, at the end of this chapter we provide several coding exercises that will help you to develop your programming skills.\nLet’s begin.",
    "crumbs": [
      "Module 1 - What is Numerical Analysis?"
    ]
  },
  {
    "objectID": "module_one.html#intro-to-numerical-analysis",
    "href": "module_one.html#intro-to-numerical-analysis",
    "title": "Module 1 - What is Numerical Analysis?",
    "section": "",
    "text": "Note\n\n\n\nSong Accompanying This Section - Are You Bored Yet? - Wallows, Clairo, Big Data\n\n\n\n\n\n\n\n\nTip\n\n\n\nIn the 1950s and 1960s, the founding fathers of Numerical Analysis discovered that inexact arithmetic can be a source of danger, causing errors in results that ought to be right. The source of such problems is numerical instability that is, the amplification of rounding errors from microscopic to macroscopic scale by certain modes of computation. Oxford Professor Lloyd (Nick) Trefethen (2006)",
    "crumbs": [
      "Module 1 - What is Numerical Analysis?"
    ]
  },
  {
    "objectID": "module_one.html#arithmetic-in-base-2",
    "href": "module_one.html#arithmetic-in-base-2",
    "title": "Module 1 - What is Numerical Analysis?",
    "section": "Arithmetic in Base 2",
    "text": "Arithmetic in Base 2\nA computer circuit knows two states: on and off. As such, anything saved in computer memory is stored using base-2 numbers. This is called a binary number system. To fully understand a binary number system it is worth while to pause and reflect on our base-10 number system for a few moments. These binary digits are called bits, and are the basis of the binary representation of numbers.\nWhat do the digits in the number \\(735\\) really mean? The position of each digit tells us something particular about the magnitude of the overall number. The number \\(735\\) can be represented as a sum of powers of \\(10\\) as\n\\[\n735 = 700 + 30 + 5 =  7 \\times 10^2 + 3 \\times 10^1 + 5 \\times 10^0\n\\]\nand we can read this number as \\(7\\) hundreds, \\(3\\) tens, and \\(5\\) ones. As you can see, in a ‘’positional number system’’ such as our base-10 system, the position of the number indicates the power of the base, and the value of the digit itself tells you the multiplier of that power. This is contrary to number systems like Roman Numerals where the symbols themselves give us the number, and meaning of the position is somewhat flexible. The number ‘’48,329’’ can therefore be interpreted as\n\\[\n48,329 = 40,000 + 8,000 + 300 + 20 + 9 = 4 \\times 10^4 + 8 \\times 10^3 + 3 \\times 10^2 + 2\n\\times 10^1 + 9 \\times 10^0,\n\\]\nFour ten thousands, eight thousands, three hundreds, two tens, and nine ones.\nNow let’s switch to the number system used by computers: the binary number system. In a binary number system the base is 2 so the only allowable digits are 0 and 1 (just like in base-10 the allowable digits were 0 through 9). In binary (base-2), the number ’‘\\(101,101\\)’’ can be interpreted as\n\\[\n101,101_2 = 1 \\times 2^5 + 0 \\times 2^4 + 1 \\times 2^3 + 1 \\times 2^2 + 0 \\times 2^1 + 1\n\\times 2^0\n\\]\n(where the subscript ‘’2’’ indicates the base to the reader). If we put this back into base 10, so that we can read it more comfortably, we get\n\\[\n101,101_2 = 32 + 0 + 8 + 4 + 0 + 1 = 45_{10}.\n\\]\nThe reader should take note that the commas in the numbers are only to allow for greater readability – we can easily see groups of three digits and mentally keep track of what we’re reading.\nExample 1.1\nConvert the number 137 from base 10 to base 2.\nSolution: One way to do the conversion is to first look for the largest power of 2 less than or equal to your number. In this case, \\(128=2^7\\) is the largest power of 2 that is less than 137. Then looking at the remainder, 9, look for the largest power of 2 that is less than this remainder. Repeat until you have the number.\n\\[\\begin{align*}\n        137_{10} &= 128 + 8 + 1 \\\\\n        &= 2^7 + 2^3 + 2^0 \\\\\n        &= 1 \\times 2^7 + 0 \\times 2^6 + 0 \\times 2^5  + 0 \\times 2^4  + 1 \\times 2^3  + 0\n        \\times 2^2  + 0 \\times 2^1  + 1 \\times 2^0  \\\\\n        &= 10001001_2\n\\end{align*}\\]\nNext we’ll work with fractions and decimals. For example, let’s take the base 10 number \\(5.341_{10}\\) and expand it out to get\n\\[\n5.341_{10} = 5 + \\frac{3}{10} + \\frac{4}{100} + \\frac{1}{1000} = 5 \\times 10^0 + 3 \\times\n10^{-1} + 4 \\times 10^{-2} + 1 \\times 10^{-3}.\n\\]\nThe position to the right of the decimal point is the negative power of 10 for the given position. We can do a similar thing with binary decimals.\nPractice\nConvert the base 10 decimal \\(0.635\\) to binary using the following steps.\n\nMultiply \\(0.635\\) by 2. The whole number part of the result is the first binary digit to the right of the decimal point.\nTake the result of the previous multiplication and ignore the digit to the left of the decimal point. Multiply the remaining decimal by 2. The whole number part is the second binary decimal digit.\nRepeat the previous step until you have nothing left, until a repeating pattern has revealed itself, or until your precision is close enough.\n\nExplain why each step gives the binary digit that it does.",
    "crumbs": [
      "Module 1 - What is Numerical Analysis?"
    ]
  },
  {
    "objectID": "module_one.html#floating-point-arithmetic",
    "href": "module_one.html#floating-point-arithmetic",
    "title": "Module 1 - What is Numerical Analysis?",
    "section": "Floating Point Arithmetic",
    "text": "Floating Point Arithmetic\nEverything stored in the memory of a computer is a number, but how does a computer actually store a number? More specifically, since computers only have finite memory we would really like to know the full range of numbers that are possible to store in a computer. Since there is a finite space in a computer, we can only ever store rational numbers (why?). Therefore, we need to know what gaps in our number system to expect when using a computer to store and do computations on numbers.\n\nConsider the number \\(x = -129.15625\\) (in base 10). This number can be converted into binary,\n\\[\nx = -123.15625_{10} = -1111011.00101_2\n\\] (you should check this).\n\nIf a computer needs to store this number, we need the binary version of scientific notation. In this case, we write\n\n\\[\nx = -1. \\underline{\\hspace{1in}} \\times 2^{\\underline{\\hspace{0.25in}}}\n\\]\n\nBased on the fact that every binary number, other than 0, can bewritten in this way, what three things do you suppose a computer needs to store for any given number?\nWhat would a computer need to store forthe binary number \\(x=10001001.1100110011_2\\)?\n\n\n\n\n\n\n\nNote\n\n\n\nFor any base-2 number \\(x\\) we can write\n\\[\nx = (-1)^{s} \\times (1+ m) \\times 2^E\n\\]\nwhere \\(s \\in \\{0,1\\}\\) is called the sign bit and \\(m\\) is a binary number such that \\(0\n\\le m &lt; 1\\).\nFor a number \\(x = (-1)^{s} \\times (1+m) \\times 2^E\\) stored in a computer, the number \\(m\\) is called the mantissa or the significand, \\(s\\) is known as the sign bit, and \\(E\\) is known as the exponent.\n\n\nExample\nWhat are the mantissa, sign bit, and exponent for the numbers \\(7_{10}\\), \\(-7_{10}\\), and \\((0.1)_{10}\\)?\nIn the last part of the previous example we saw that the number \\((0.1)_{10}\\) is actually a repeating decimal in base-2. This means that in order to completely represent the number \\((0.1)_{10}\\) in base-2, we need infinitely many decimal places. Obviously that can’t happen since we are dealing with computers with finite memory. Over the course of the past several decades there have been many systems developed to properly store numbers. The IEEE standard that we now use is the accumulated effort of many computer scientists, much trial and error, and deep scientific research. We now have three standard precisions for storing numbers on a computer, single, double, and extended precision. The double precision standard is what most of our modern computers use.\nThere are three standard precisions for storing numbers in a computer. * A single-precision number consists of 32 bits, with 1 bit for the sign, 8 for the exponent, and 23 for the significand. * A double-precision number consists of 64 bits with 1 bit for the sign, 11 for the exponent, and 52 for the significand. * An extended-precision number consists of 80 bits, with 1 bit for the sign, 15 for the exponent, and 64 for the significand.\nMachine precision is the gap between the number 1 and the next larger floating point number. Often it is represented by the symbol \\(\\epsilon\\). To clarify, the number 1 can always be stored in a computer system exactly and if \\(\\epsilon\\) is machine precision for that computer then \\(1+\\epsilon\\) is the next largest number that can be stored with that machine.\nFor all practical purposes the computer cannot tell the difference between two numbers if the difference is smaller than machine precision. This is of the utmost important when you want to check that something is “zero” since a computer just cannot know the difference between \\(0\\) and \\(\\epsilon\\).\n\nAdditional Resources\n\nNumber Representation in Computers\nFloating Point Arithmetic",
    "crumbs": [
      "Module 1 - What is Numerical Analysis?"
    ]
  },
  {
    "objectID": "module_one.html#approximating-functions",
    "href": "module_one.html#approximating-functions",
    "title": "Module 1 - What is Numerical Analysis?",
    "section": "Approximating Functions",
    "text": "Approximating Functions\nNumerical analysis is all about doing mathematics on a computer in accurate and predictable ways. Since a computer can only ever store finite bits of information for any number, most of what we do in a computer is naturally an approximation of the real mathematics. In this section we will look at a very powerful way to approximate mathematical functions.\nHow does a computer understand a function like \\(f(x) = e^x\\)? What happens under the hood, so to speak, when you ask a computer to do a computation with one of these functions? A computer is very good at arithmetic, but working with transcendental functions like these, or really any other sufficiently complicated functions for that matter, causes all sorts of problems in a computer. Approximation of the function is something that is always happening under the hood.\nIn the previous exercises, you have built up some basic intuition for what we would want out of a mathematical operation that might build an approximation of a complicated function. What we’ve built is actually a way to get better and better approximations for functions out to pretty much any arbitrary accuracy that we like so long as we are near some anchor point (which we called \\(x_0\\))\nOne of the points of this whole discussion is to give you a little glimpse as to what is happening behind the scenes in scientific programming languages when you do computations with these functions. A bigger point is to start getting a feel for how we might go in reverse and approximate an unknown function out of much simpler parts. This last goal is one of the big takeaways from numerical analysis: we can mathematically model highly complicated functions out of fairly simple pieces.\nDefinition. Taylor Series) If \\(f(x)\\) is an infinitely differentiable function at the point \\(x_0\\), then the infinite polynomial expansion is called the Taylor Series of the function \\(f(x)\\)\n\\[\nf(x) = \\sum\\limits^{\\infty}_{k=0} \\frac{f^{(k)}(x_0)}{k!} (x - x_0)^k\n\\]\nTaylor Series are named for the mathematician Brook Taylor.",
    "crumbs": [
      "Module 1 - What is Numerical Analysis?"
    ]
  },
  {
    "objectID": "module_one.html#approximation-error-con-taylor-series",
    "href": "module_one.html#approximation-error-con-taylor-series",
    "title": "Module 1 - What is Numerical Analysis?",
    "section": "Approximation Error (con Taylor Series)",
    "text": "Approximation Error (con Taylor Series)\nThe great thing about Taylor Series is that they allow for the representation of potentially very complicated functions as polynomials – and polynomials are easily dealt with on a computer since they involve only addition, subtraction, multiplication, division, and integer powers. The down side is that the order of the polynomial is infinite. Hence, every time we use a Taylor series on a computer we are actually going to be using a Truncated Taylor Series where we only take a finite number of terms. The idea here is simple in principle\n\nIf a function \\(f(x)\\) has a Taylor Series representation it can be written as an infinite sum.\nComputers can’t do infinite sums.\nSo stop the sum at some point \\(n\\) and throw away the rest of the infinite sum.\nNow \\(f(x)\\) is approximated by some finite sum so long as you stay pretty close to \\(x=x_0\\)\nand everything that we just removed of the end is called the remainder for the finite sum.\n\n\n\n\n\n\n\nTipTheorem 1.1\n\n\n\nThe approximation error when using a truncated Taylor Series is roughly proportional to the size of the next term in the Taylor Series.",
    "crumbs": [
      "Module 1 - What is Numerical Analysis?"
    ]
  },
  {
    "objectID": "week1.html",
    "href": "week1.html",
    "title": "1  Week 1 - Intro to Numerical Analysis",
    "section": "",
    "text": "1.1 Philosophies for this Course\nFor this course, there will be a weekly participation notebooks. During each class session, you will have time to complete portions of these notebooks. The goal is for you to complete at least 90% of the notebook in class and this should very rarely be an additional ‘homework’ assignment. If you miss class, it is your responsibility to complete the notebook, ask questions, and turn it in by Friday.\nTo begin all assignments (whether participation or homework), please save a copy of this notebook to your Google Drive by clicking the Google Colab buttom at the top of this notebook. Be sure to check Canvas for due dates and reminders.",
    "crumbs": [
      "Module 1 - What is Numerical Analysis?",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1 - Intro to Numerical Analysis</span>"
    ]
  },
  {
    "objectID": "week1.html#philosophies-for-this-course",
    "href": "week1.html#philosophies-for-this-course",
    "title": "1  Week 1 - Intro to Numerical Analysis",
    "section": "",
    "text": "TIMTOWDI (Tim Toady)\nWrite Working Code First, Optimize Second\n\n\n1.1.1 Best practices\n\nFor coding environments, provide detailed comments for interpretability and reproducibility. This will also help the future you when you come back to past assignments/code.\nRead the error message when your code does not work. They contain important information on how to debug your code.\nIf you do something more than twice, automate that action.\nWrite code that works first, then optimize!\nNotebooks can be split if they get too long. You want to be able to come back to a notebook without too much trouble and searching.",
    "crumbs": [
      "Module 1 - What is Numerical Analysis?",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1 - Intro to Numerical Analysis</span>"
    ]
  },
  {
    "objectID": "week1.html#introduction-to-python-and-colab",
    "href": "week1.html#introduction-to-python-and-colab",
    "title": "1  Week 1 - Intro to Numerical Analysis",
    "section": "1.2 Introduction to Python and Colab",
    "text": "1.2 Introduction to Python and Colab\n\nThis introduction to Jupyter Notebook is based on tutorials developed by Jessica Hamrick.\n\nThe notebook consists of a series of cells. For example, this text is in what is called a “Markdown cell”.\nThese cells support \\(\\LaTeX\\) and a variety of other features (see toolbar above).\nPractice: Add a Markdown cell below and use at least 3 of the options from the toolbar (for example, bold, inserting a link, a picture, LaTeX, etc.)\nThe following cell is a “code cell”:\n\n# this is a code cell\n# this is a comment - comments are for you or for anyone else reading your work\n\n# multiply example\n29 * 21\n\n# division\n28/7\n\n\n1.2.1 Executing cells\nCode cells can contain any valid Python code in them. When you run the cell, the code is executed and any output is displayed.\n\nYou can execute cells with Ctrl-Enter (which will keep the cell selected), or Shift-Enter (which will select the next cell).\n\nTry running the following cell and see what it prints out:\n\n# print() is a function that prints what is in the parentheses (usually in quotes)\nprint(\"Printing the numbers from 1-10:\")\n\n# this is a for loop which repeats the command inside of the indented space\nfor i in range(1, 11):\n  # print using f strings\n  print(f\"{i}\")\n# print another message\nprint(\"Done printing numbers.\")\n\nPractice: Copy and paste the code from above into the code cell below and change the numbers in the parentheses of range. What do you observe?\n\n\n1.2.2 Python Kernel\nWhen you first start a notebook, you are also starting what is called a kernel. This is a special program that runs in the background and executes code (by default, this is Python, but it could be other languages too, like R!). Whenever you run a code cell, you are telling the kernel to execute the code that is in the cell, and to print the output (if any).\nJust like if you were typing code at the Python interpreter, you need to make sure your variables are declared before you can use them. What will happen when you run the following cell? Try it and see:\n\na\n\nWhat does the error tell you?\nLet’s modify the cell above so that a is declared first.\n\n# here, we define a\na = 4\na\n\nNow let’s write a comment on the code cell above.\nSome random/built-in functions are\n\nabs()\nhelp()\nprint()\n\n\n# if I wanted more about abs(), I could use the help() function\nhelp(abs)\n\nPractice: What are some other built-in functions in Python (feel free to look them up)? Get help on one of the ones that are not listed above.\n\nabs(-4)\n\n\n# other functions people searched\n# ascii, bin, sum",
    "crumbs": [
      "Module 1 - What is Numerical Analysis?",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1 - Intro to Numerical Analysis</span>"
    ]
  },
  {
    "objectID": "week1.html#intro-to-numerical-analysis",
    "href": "week1.html#intro-to-numerical-analysis",
    "title": "1  Week 1 - Intro to Numerical Analysis",
    "section": "1.3 Intro to Numerical Analysis",
    "text": "1.3 Intro to Numerical Analysis\nPractice\nBy hand (no computers!) compute the first 12 terms of this sequence with the initial condition \\(x_0 = 1/10\\).\n\\[\nx_{n+1} = \\left\\{ \\begin{array}{ll} 2x_n, & x_n \\in [0,\\frac{1}{2}] \\\\ 2x_n - 1, & x_n \\in (\\frac{1}{2},1] \\end{array} \\right.\n\\]\n\\[\n1/10, 2/10, 4/10, 8/10, 6/10, 2/10, 4/10, 8/10, 6/10, 2/10,\n\\]\nPractice\nNow use a spreadsheet and to do the computations. Do you get the same answers?\n[ Put your response here + a link to your Google Sheet ]\nPractice Finally, solve this problem with Python. Some starter code is given to you below.\n# define x\nx = 1.0/10\n# calculate the first 50 terms using this rule\nfor n in range(50):\n  # check if the first condition is met\n    if :\n        # put the correct assignment here\n        \n  # if the first condition is not met, do this\n    else:\n        # put the correct assigment here\n    print(x)\nPractice\nWhat do you notice? What do you think happened on the computer and why did it give you a different answer? What, do you suppose, is the cautionary tale hiding behind the scenes with this problem?\nWhat I noticed is. …\nPractice\nNow what happens with this problem when you start with \\(x_0 = 1/8\\)?",
    "crumbs": [
      "Module 1 - What is Numerical Analysis?",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1 - Intro to Numerical Analysis</span>"
    ]
  },
  {
    "objectID": "week1.html#arithmetic-in-base-2",
    "href": "week1.html#arithmetic-in-base-2",
    "title": "1  Week 1 - Intro to Numerical Analysis",
    "section": "1.4 Arithmetic in Base 2",
    "text": "1.4 Arithmetic in Base 2\nPractice\nExpress the following binary numbers in base-10.\n\n\n\\(111_2\\)\n\n\n\\(10,101_2\\)\n\n\nPractice\nDiscussion: With your group discuss how you would convert a base-10 number into its binary representation. Once you have a proposed method, apply it to the number \\(237_{10}\\) who’s base-2 expression is \\(11,101,101_2\\)?\nPractice\nConvert the base 10 fraction \\(1/10\\) into binary. Use your solution to fully describe what went wrong in problems\n\n# calculating binary of a number + bit size of a variable\na = 7\nbin(a)\na.bit_length()",
    "crumbs": [
      "Module 1 - What is Numerical Analysis?",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Week 1 - Intro to Numerical Analysis</span>"
    ]
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "2  Week 2: Approximating Functions",
    "section": "",
    "text": "2.1 Floating Point Arithmetic\n# calculating binary of a number + bit size of a variable\na = 7\nbin(a)\na.bit_length()\nPractice\nWhat are the mantissa, sign bit, and exponent for the numbers \\(7_{10}\\), \\(-7_{10}\\), and \\((0.1)_{10}\\)?\nPractice\nTo make all of these ideas concrete, let’s consider with a small computer system where each number is stored in the following format:\n\\[\ns\\; E\\; b_1 b_2 b_3\n\\]\nThe first entry is a bit for the sign (0\\(=+\\) and \\(1=-\\)). The second entry, \\(E\\) is for the exponent, and we’ll assume in this example that the exponent can be 0, 1, or -1. The three bits on the right represent the significand of the number. Hence, every number in this number system takes the form\n\\[\n(-1)^s \\times (1+ 0.b_1b_2b_3) \\times 2^{E}\n\\]",
    "crumbs": [
      "Module 1 - What is Numerical Analysis?",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 2: Approximating Functions</span>"
    ]
  },
  {
    "objectID": "week2.html#floating-point-arithmetic",
    "href": "week2.html#floating-point-arithmetic",
    "title": "2  Week 2: Approximating Functions",
    "section": "",
    "text": "What is the smallest positive number that can be represented in this form?\nWhat is the largest positive number that can be represented in this form?\nWhat is the machine precision in this number system?",
    "crumbs": [
      "Module 1 - What is Numerical Analysis?",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 2: Approximating Functions</span>"
    ]
  },
  {
    "objectID": "week2.html#approximating-functions",
    "href": "week2.html#approximating-functions",
    "title": "2  Week 2: Approximating Functions",
    "section": "2.2 Approximating Functions",
    "text": "2.2 Approximating Functions\nPractice\nIn this problem we’re going to make a bit of a wish list for all of the things that a computer will do when approximating a function. We’re going to complete the following sentence: If we are going to approximate \\(f(x)\\) near the point \\(x=x_0\\) with a simpler function \\(g(x)\\) then …\n(I’ll get us started with the first item that seems natural to wish for. The rest of the wish list is for you to complete.)\n\nthe functions \\(f(x)\\) and \\(g(x)\\) should agree at \\(x=x_0\\). In other words, \\(f(x_0) = g(x_0)\\)\nif \\(f(x)\\) is increasing/decreasing to the right of \\(x=x_0\\), then \\(g(x)\\) …\nif \\(f(x)\\) is increasing/decreasing to the left of \\(x=x_0\\), then \\(g(x)\\) …\nif \\(f(x)\\) is concave up/down to the right of \\(x=x_0\\), then \\(g(x)\\) …\nif \\(f(x)\\) is concave up/down to the left of \\(x=x_0\\), then \\(g(x)\\) …\n… is there anything else you would add?\n\nPractice\nLet \\(f(x) = e^x\\). Based on the lecture notes, build a cubic polynomial (Taylor Series) that approximates \\(f(x)=e^x\\) near \\(x_0 = 0\\).\n\\[\ne^x \\approx 1 + x + \\frac{x^2}{2} + \\frac{x^3}{6}\n\\]\nNow, we will practice plotting some of our approximations.\n\n# import packages\nimport numpy as np\nfrom plotly import graph_objs as go\n\n# data points along the x axis\n# your comments go here\nxdata = np.linspace(start = -3, stop = 3, num = 50)\n\n# data points along the y axis (y = e^x)\nyexp = np.exp(xdata)\n#y1 = xdata**2\n\n\n#yexp\ny1 = 1 + xdata + (xdata**2)/2 + (xdata**3)/6\ny1\n\n\n# define a single plot\nfig = go.Figure(go.Scatter(x=xdata, y=yexp, name='$f(x) = e^x$'))\n\n# adding a trace\nfig.add_trace(go.Scatter(x=xdata, y=y1, name=r'$1 + x + \\frac{x^2}{2} + x^3/6$'))\n\nfig.update_layout(title = 'Plot of f(x)')\nfig.show()\n\nPractice Consider the function\n\\[\nf(x) = \\frac{1}{1-x}\n\\]\nand build a Taylor Series centered at \\(x_0 = 0\\).\nPlot the function, and at least 2 approximations. What do you notice?\n\n# define the new function\nfx = 1/(1-xdata)\n# define approximation\nfx_approx = 1 + xdata + xdata**2",
    "crumbs": [
      "Module 1 - What is Numerical Analysis?",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 2: Approximating Functions</span>"
    ]
  },
  {
    "objectID": "week2.html#approximation-error-con-taylor-series",
    "href": "week2.html#approximation-error-con-taylor-series",
    "title": "2  Week 2: Approximating Functions",
    "section": "2.3 Approximation Error (con Taylor Series)",
    "text": "2.3 Approximation Error (con Taylor Series)\nDiscussion Q: With the function from the previous exercise, what is the expected and absolute error of the linear, quadratic, and cubic function when trying to approximate \\(e^{0.1}\\) (np.exp(0.1))\n\nComplete the table below.\nAdd a plot (with appropriate labels) of your approximations.\n\n\n\n\nTaylor Series\nApprox.\nAbsolute Error\nExpected Error\n\n\n\n\n0th order\n1\n0.10517\nO(\\(x\\)) = 0.1\n\n\n1st order\n1.1\n0.00517\nO(\\(x^2\\)) = 0.01\n\n\n2nd order\n\n\n\n\n\n3rd order\n\n\n\n\n\n\n\nabs(np.exp(0.1) - 1)\n\nPractice How does the error change when you approximate \\(f(x) = e^x\\) centered at \\(x_0=1\\)?\n\nAdd a table to support your conclusions.\nAdd a plot (with appropriate labels) of your approximations.\n\nPractice Write the Taylor Series for \\(f(x) = \\sin(x)\\) centered at \\(x_0=0\\). How is this error different from the one when \\(f(x) = e^x\\)?\n\nAdd a table to support your conclusions.\nAdd a plot (with appropriate labels) of your approximations.",
    "crumbs": [
      "Module 1 - What is Numerical Analysis?",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Week 2: Approximating Functions</span>"
    ]
  },
  {
    "objectID": "module_two.html",
    "href": "module_two.html",
    "title": "Module 2 - Numerical Calculus",
    "section": "",
    "text": ".. to be added :]",
    "crumbs": [
      "Module 2 - Numerical Calculus"
    ]
  },
  {
    "objectID": "week3.html",
    "href": "week3.html",
    "title": "3  Week 3: Numerical Calculus Intro",
    "section": "",
    "text": "3.1 Numerical Calculus\nIn this module, we build some of the common techniques for approximating the two primary computations in calculus: taking derivatives and evaluating definite integrals.\nPractice\nIn statistics, the function known as the normal distribution (the bell curve) is defined as\n\\[\nN(x) = \\frac{1}{\\sqrt{2 \\pi}} e^{-x^2/2}.\n\\]\nOne of the primary computations of introductory statistics is to find the area under a portion of this curve since this area gives the probability of some event\n\\[\nP(a &lt; x &lt; b) = \\int^b_a \\frac{1}{\\sqrt{2 \\pi}} e^{-x^2/2}\\;dx.\n\\]\nThe trouble is that there is no known antiderivative of this function.\nPropose a method for approximating this area.\nfrom plotly import graph_objs as go\n\n# plotting N(x) by first defining xdata\nxdata = np.linspace(-3,3)\nN = 1/(np.sqrt(2*np.pi)) * np.exp(-xdata**2/2)\n\nfig=go.Figure()\nfig.add_trace(go.Scatter(x=xdata, y=N))\nPractice\nGive a list of five functions for which an exact algebraic derivative is relatively easy but an exact antiderivative is either very hard or maybe impossible. Be prepared to compare with your peers.\nSome functions could be - \\(\\sin(x^2)\\) - \\(e^{x^2}\\) - \\(\\log_{10}(x) \\ln(x)\\) - \\(\\frac{1}{\\ln (x)}\\)",
    "crumbs": [
      "Module 2 - Numerical Calculus",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 3: Numerical Calculus Intro</span>"
    ]
  },
  {
    "objectID": "week3.html#numerical-calculus",
    "href": "week3.html#numerical-calculus",
    "title": "3  Week 3: Numerical Calculus Intro",
    "section": "",
    "text": "…",
    "crumbs": [
      "Module 2 - Numerical Calculus",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 3: Numerical Calculus Intro</span>"
    ]
  },
  {
    "objectID": "week3.html#differentiation",
    "href": "week3.html#differentiation",
    "title": "3  Week 3: Numerical Calculus Intro",
    "section": "3.2 Differentiation",
    "text": "3.2 Differentiation\nIn this section we’ll build several approximation of first and second derivatives. The idea for each of these approximation is:\n\nPartition the interval \\([a,b]\\) into \\(N\\) points.\nDefine the distance between two points in the partition as \\(h\\).\nApproximate the derivative at the point \\(x \\in [a,b]\\) by using linear combinations of \\(f(x-h)\\), \\(f(x)\\), \\(f(x+h)\\), and/or other points in the partition.\n\nThis converts a continuous problem to a discrete problem.\nPractice\nLet’s take a close look at partitions before moving on to more details about numerical differentiation.\nIf we partition the interval [0,1] into 3 equal sub intervals each with length \\(h\\), then:\n\n$h = $\n\\([0,1] = [0,-] \\cup [-,-], \\cup [-, 1]\\)\nThere are four total points that define the partition. They are \\(0, - , - , 1\\)\n\nNote: In general, for a closed interval \\([a,b]\\), with \\(N\\) equal sub intervals, we have\n\\[\nh = \\frac{b - a}{N}\n\\]\n\n# using numpy to do this for us\n\nnp.linspace(0,1,5)\n\n# Q: how would we partition [5,10] into 100 equal sub intervals?\nnp.linspace(start = 5, stop = 10, num=101)\n\n\nnp.linspace(0,1,4)\n\nIf we recall that the definition of the first derivative of a function is\n\\[\\begin{align}\n    \\frac{df}{dx} = \\lim_{h \\to 0} \\frac{f(x+h) - f(x)}{h}.\n\\end{align}\\]\nour first approximation for the first derivative is naturally\n\\[\\begin{align}\n    \\frac{df}{dx} \\approx \\frac{f(x+h) - f(x)}{h}.\n\\end{align}\\]\nFrom Taylor’s Theorem we know that for an infinitely differentiable function \\(f(x)\\),\n\\[\\begin{align*}\nf(x) &= f(x_0) + \\frac{f'(x_0)}{1!} (x-x_0)^1\\\\ &+ \\frac{f''(x_0)}{2!}(x-x_0)^2 + \\frac{f^{(3)}(x_0)}{3!}(x-x_0)^3\\\\\n&+ \\frac{f^{(4)}(x_0)}{4!}(x-x_0)^4 + \\cdots.\n\\end{align*}\\]\nWhat do we get if we replace \\(x\\) (in the Taylor Series) with \\(x+h\\) and replace every \\(x_0\\) in the series with \\(x\\)? In other words, what is\n\\[\nf(x + h) =\n\\]\nPractice\nSolve the result from the previous problem for \\(f'(x)\\) to create an approximation for \\(f'(x)\\) using \\(f(x+h), f(x)\\) and higher-order terms (fill in the ?),\n\\[\nf'(x) = \\frac{??? - ???}{?} +  ???\n\\]",
    "crumbs": [
      "Module 2 - Numerical Calculus",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 3: Numerical Calculus Intro</span>"
    ]
  },
  {
    "objectID": "week3.html#error-analysis",
    "href": "week3.html#error-analysis",
    "title": "3  Week 3: Numerical Calculus Intro",
    "section": "3.3 Error Analysis",
    "text": "3.3 Error Analysis\nPractice\nConsider the function \\(f(x) = \\sin(x)(1-x)\\). The goal of this problem is to make sense of the discussion of the “order” of the derivative approximation.\n\nFind f’(x) by hand\nVerify that \\(f'(1) = -\\sin(1) \\approx -0.841471\\)\nTo approximate the first derivative at \\(x=1\\) numerically with our first order approximation formula, we calculate\n\n\n\n\n\\(h\\)\nApprox. of \\(f'(1)\\)\nExact Value of \\(f'(1)\\)\nAbs. % Error\n\n\n\n\n\\(2^{-1}\\)\n\n-0.841471\n18.54181%\n\n\n\\(2^{-2}\\)\n\n-0.841471\n\n\n\n\\(2^{-3}\\)\n\n-0.841471\n\n\n\n\nThe following code will help automate this process\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nexact = -np.sin(1) # what does this line do?\nH = 2.0**(-np.arange(1,10)) # what does this line do?\nAbsPctError = [] # start off with a blank list of errors\n\nfor h in H:\n  approx = # FINISH THIS LINE OF CODE\n  AbsPctError.append( np.abs( (approx - exact)/exact ) )\n  if h==H[0]:\n    print(\"h=\",h,\"\\t Absolute Pct Error=\", AbsPctError[-1])\n  else:\n    err_reduction_factor = AbsPctError[-2]/AbsPctError[-1]\n    print(\"h=\",h,\"\\t Absolute Pct Error=\", AbsPctError[-1],\n              \"with error reduction\",err_reduction_factor)\n\nplt.loglog(H,AbsPctError,'b-*') # Why are we build a loglog plot?\nplt.grid()\nplt.show()",
    "crumbs": [
      "Module 2 - Numerical Calculus",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Week 3: Numerical Calculus Intro</span>"
    ]
  },
  {
    "objectID": "week4.html",
    "href": "week4.html",
    "title": "4  Week 4 - Error Analysis & Integration Intro",
    "section": "",
    "text": "4.1 Error Analysis\nPractice\nConsider the function \\(f(x) = \\sin(x)(1-x)\\). The goal of this problem is to make sense of the discussion of the “order” of the derivative approximation.\n\\[\n\\frac{f(1+h) - ??}{??}\n\\]\n# let's start with defining h\nh = 2**(-3)\nprint('The step size is',h)\n\n# define approximation as out\nout = (np.sin(1+h)*(1-1-h) - np.sin(1)*0)/h\nprint('The approximation is', out)\n# define exact\nprint('The exact value is', -np.sin(1))\n# the absolute % error\nprint('The absolute % error is', abs(out - -np.sin(1))/np.sin(1) * 100)\n\nThe step size is 0.125\nThe approximation is -0.9022675940990952\nThe exact value is -0.8414709848078965\nThe absolute % error is 7.225039292956516\nThe following code will help automate this process\n2.0**(-np.arange(1,10))\n\narray([0.5       , 0.25      , 0.125     , 0.0625    , 0.03125   ,\n       0.015625  , 0.0078125 , 0.00390625, 0.00195312])\n# import packages\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# define the exact value of f'(1)\nexact = -np.sin(1)\n# create an array of stepsizes from 2^(-1) to 2^(-10)\nH = 2.0**(-np.arange(1,10))\nAbsPctError = [] # start off with a blank list of errors\n\nfor h in H:\n  # define approximation\n  approx = # FILL THIS IN\n  # calculate the abs percent error\n  AbsPctError.append( np.abs( (approx - exact)/exact ) )\n  if h==H[0]:\n    print(\"h=\",h,\"\\t Absolute Pct Error=\", AbsPctError[-1])\n  else:\n    err_reduction_factor = AbsPctError[-2]/AbsPctError[-1]\n    print(\"h=\",h,\"\\t Absolute Pct Error=\", AbsPctError[-1],\n              \"with error reduction\",err_reduction_factor)\n\nplt.loglog(H,AbsPctError,'b-*') # Why are we build a loglog plot?\nplt.grid()\nplt.show()\n\nh= 0.5   Absolute Pct Error= 0.1854181601184709\nh= 0.25      Absolute Pct Error= 0.12776867710089196 with error reduction 1.4512020029138777\nh= 0.125     Absolute Pct Error= 0.07225039292956516 with error reduction 1.7684149790776915\nh= 0.0625    Absolute Pct Error= 0.03815217748298682 with error reduction 1.8937423155410655\nh= 0.03125   Absolute Pct Error= 0.019573887040617487 with error reduction 1.9491364900501262\nh= 0.015625      Absolute Pct Error= 0.009910221068472835 with error reduction 1.9751211305353678\nh= 0.0078125     Absolute Pct Error= 0.004985780110301419 with error reduction 1.9876971806271069\nh= 0.00390625    Absolute Pct Error= 0.00250053851755135 with error reduction 1.9938825478216344\nh= 0.001953125   Absolute Pct Error= 0.0012521789951432975 with error reduction 1.9969497390149018",
    "crumbs": [
      "Module 2 - Numerical Calculus",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Week 4 - Error Analysis & Integration Intro</span>"
    ]
  },
  {
    "objectID": "week4.html#error-analysis",
    "href": "week4.html#error-analysis",
    "title": "4  Week 4 - Error Analysis & Integration Intro",
    "section": "",
    "text": "Find f’(x) by hand\nVerify that \\(f'(1) = -\\sin(1) \\approx -0.841471\\)\nTo approximate the first derivative at \\(x=1\\) numerically with our first order approximation formula, we calculate\n\n\n\n\n\n\\(h\\)\nApprox. of \\(f'(1)\\)\nExact Value of \\(f'(1)\\)\nAbsolute % Error\n\n\n\n\n\\(2^{-1}\\)\n\n-0.841471\n\\(\\frac{|A - E|}{E} \\times 100 =\n18.54181\n\\%\\)\n\n\n\\(2^{-2}\\)\n\n-0.841471\n\n\n\n\\(2^{-3}\\)\n\n-0.841471",
    "crumbs": [
      "Module 2 - Numerical Calculus",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Week 4 - Error Analysis & Integration Intro</span>"
    ]
  },
  {
    "objectID": "week4.html#efficient-coding",
    "href": "week4.html#efficient-coding",
    "title": "4  Week 4 - Error Analysis & Integration Intro",
    "section": "4.2 Efficient Coding",
    "text": "4.2 Efficient Coding\nNow, let’s build a Python function that accepts * a mathematical funciton * the bounds of an interval, * and the number of subintervals.\nSome notes: * We can build Python functions in two ways: - First, we can use the following format python   def funname(input):     #some operation     return output - Next, we can use lambda functions (in one line) python   funname = lambda x: #some operation with x\n\nA lambda function is a small anonymous function and usually only takes up one line of code\nA lambda function can take any number of arguments, but can only have one expression.\n\n\ndef mydiv(a,b):\n\n\n# lambda function\nmydiv2 = lambda x, y: x/y\n\n\nmydiv2(5,2)\n\n2.5\n\n\n\ndef FirstDeriv(f, a, b, N):\n  # define the grid\n  x = np.linspace(a,b,N+1)\n  # define the step size\n  h = x[1] - x[0]\n  # create an empty array for the first derivative\n  df = []\n\n  # calculate the deriv approx at each point\n  for j in np.arange(len(x) - 1):\n    df.append((f(x[j+1]) - f(x[j]))/ h )\n\n  return df\n\n\n# define f as lambda function w/ sin(x)\nf = ...\n# define the derivative with a lambda function\nexact_df = ...\n# define the end points and number of sub intervals\na = ...\nb = ...\nN = ...\n# define x (for the plotting)\nx = ...\n\n# apply FirstDeriv function, save to df\ndf = ...\n\n\nfig = go.Figure()\n\nfig.add_trace(go.Scatter(x=x, y=f(x),  name='f(x) = sin(x)'))\nfig.add_trace(go.Scatter(x=x, y=exact_df(x), name='exact first deriv.'))\nfig.add_trace(go.Scatter(x=x, y=df, name = 'approx first deriv.'))\n\nOutput hidden; open in https://colab.research.google.com to view.\n\n\nChange \\(a, b,\\) or \\(N\\) and write one or two observations you see.",
    "crumbs": [
      "Module 2 - Numerical Calculus",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Week 4 - Error Analysis & Integration Intro</span>"
    ]
  },
  {
    "objectID": "week4.html#integration",
    "href": "week4.html#integration",
    "title": "4  Week 4 - Error Analysis & Integration Intro",
    "section": "4.3 Integration",
    "text": "4.3 Integration\nPractice\nConsider the shaded area of the region under the function between \\(x=0\\) and \\(x=2\\).\n\n\nWhat rectangle (with area 6) gives an upper bound for the area under the curve? Can you give a better upper bound?\nWhy must the area under the curve be greater than 3?\nIs the area greater than 4? Why/Why not?\nWork with your partner to give an estimate of the area and provide an estimate for the amount of error that you’re making.\n\nEstimates:\n\narea_est = []\nnp.mean(area_est)\n\n3.6835833333333334\n\n\nPractice\nWrite code to approximate an integral with Riemann sums. You should ALWAYS start by writing pseudo-code as comments in your function. Your Python function should accept a Python Function, a lower bound, an upper bound, the number of subintervals. Test your code on several functions for which you know the integral. You should write your code without any loops.\nWe need: * step size - \\(\\Delta x = h\\) * \\(f(x)\\) * we need the bounds \\(a,b\\) * for Left-aligned R.S., we need the function values at the ‘left’ points in the interval \\([a,b]\\)\n\ndef riemann_left(f, a, b, N):\n  x = np.linspace(a,b,N+1)\n  h = x[1] - x[0]\n  print(h)\n  print(x)\n  areas = f(x[0:N])*h # Q: how does this only evaluate at left points?\n  rsum = sum(areas)\n\n  return rsum\n\n\nf = lambda x: np.cos(x)\n\na = 0\nb = 1\nN = 8\n\nriemann_left(f, a, b, N)\n\n0.125\n[0.    0.125 0.25  0.375 0.5   0.625 0.75  0.875 1.   ]\n\n\n0.8691061399106281\n\n\nTheorem\nIn approximating the integral \\(\\int_a^b f(x) dx\\) with a fixed interval width \\(\\Delta x\\) we find an absolute percent error \\(P\\).\n\nIf we use left rectangles and an interval width of \\(\\frac{\\Delta x}{M}\\) then the absolute percent error will be approximately \\(\\underline{\\hspace{1in}}\\).\nIf we use right rectangles and an interval width of \\(\\frac{\\Delta x}{M}\\) then the absolute percent error will be approximately \\(\\underline{\\hspace{1in}}\\).\n\nThe previous theorem could be stated in an equivalent way.\nIn approximating the integral \\(\\int_a^b f(x) dx\\) with a fixed interval number of subintervals we find an absolute percent error \\(P\\).\n\nIf we use left rectangles and \\(M\\) times as many subintervals then the absolute percent error will be approximately \\(\\underline{\\hspace{1in}}\\).\nIf we use right rectangles and \\(M\\) times as many subintervals then the absolute percent error will be approximately \\(\\underline{\\hspace{1in}}\\).",
    "crumbs": [
      "Module 2 - Numerical Calculus",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Week 4 - Error Analysis & Integration Intro</span>"
    ]
  },
  {
    "objectID": "week5.html",
    "href": "week5.html",
    "title": "5  Week 5 - Integration",
    "section": "",
    "text": "5.1 Integration\nPractice\nWrite code to approximate an integral with Riemann sums. You should ALWAYS start by writing pseudo-code as comments in your function. Your Python function should accept a Python Function, a lower bound, an upper bound, the number of subintervals. Test your code on several functions for which you know the integral. You should write your code without any loops.\nWe need: * step size - \\(\\Delta x = h\\) * \\(f(x)\\) * we need the bounds \\(a,b\\) * for Left-aligned R.S., we need the function values at the ‘left’ points in the interval \\([a,b]\\)\ndef riemann_left(f, a, b, N):\n  x = np.linspace(a,b,N+1)\n  h = x[1] - x[0]\n  areas = f(x[0:N])*h # Q: how does this only evaluate at left points?\n  rsum = sum(areas)\n\n  return rsum\nf = lambda x: np.cos(x)\n\na = 0\nb = 1\nN = 1000\n\nriemann_left(f, a, b, N)\n\n0.8417007635323798\nTheorem\nIn approximating the integral \\(\\int_a^b f(x) dx\\) with a fixed interval width \\(\\Delta x\\) we find an absolute percent error \\(P\\).\nThe previous theorem could be stated in an equivalent way.\nIn approximating the integral \\(\\int_a^b f(x) dx\\) with a fixed interval number of subintervals we find an absolute percent error \\(P\\).\nThe order of these methods (left and right Riemann rectangles) is \\(\\mathcal{O}(\\Delta x)\\).",
    "crumbs": [
      "Module 2 - Numerical Calculus",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Week 5 - Integration</span>"
    ]
  },
  {
    "objectID": "week5.html#integration",
    "href": "week5.html#integration",
    "title": "5  Week 5 - Integration",
    "section": "",
    "text": "If we use left rectangles and an interval width of \\(\\frac{\\Delta x}{M}\\) then the absolute percent error will be approximately \\(\\underline{\\hspace{1in}}\\).\nIf we use right rectangles and an interval width of \\(\\frac{\\Delta x}{M}\\) then the absolute percent error will be approximately \\(\\underline{\\hspace{1in}}\\).\n\n\n\n\nIf we use left rectangles and \\(M\\) times as many subintervals then the absolute percent error will be approximately \\(\\underline{\\hspace{1in}}\\).\nIf we use right rectangles and \\(M\\) times as many subintervals then the absolute percent error will be approximately \\(\\underline{\\hspace{1in}}\\).\n\n\n\n5.1.1 Trapezoidal Rule\n\nThe function shown in the picture is \\(f(x) = \\frac{1}{5} x^2 (5-x)\\).\nPractice\nWhat is the area under the function from \\([1,4]\\) when \\(\\Delta x = 1\\)?\n\nf = lambda x: 1/5*x**2*(5-x)\nprint(f(1)+f(2))\nprint(f(2)+f(3))\nprint(f(3)+f(4))\n\n3.2\n6.0\n6.800000000000001\n\n\nANS:\n\\[\\begin{align*}\nA &= A_1 + A_2 + A_3\\\\\n&= \\vdots\\\\\n&= \\vdots\\\\\n&= \\vdots\\\\\n\\end{align*}\\]\nPractice\nWrite code to give the trapezoidal rule approximation for the definite integral \\(\\int^b_a f(x)\\;dx\\). Test your code on functions where you know the definite area.\n\ndef trapRULE(a, b, N, f):\n  ...\n  return rsum\n\nPractice\nUse the code that you wrote in the previous problem to test your conjecture about the order of the approximation error for the trapezoid rule. Integrate the function \\(f(x) = \\sin(x)\\) from \\(x=0\\) to \\(x=1\\) with more and more trapezoids. In each case compare to the exact answer and find the absolute percent error. The goal is to answer the question:\nIf we calculate the definite integral with a fixed \\(\\Delta x\\) and get an absolute percent error, \\(P\\), then what absolute percent error will we get if we use a width of \\(\\Delta x/M\\) for some positive number \\(M\\)?",
    "crumbs": [
      "Module 2 - Numerical Calculus",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Week 5 - Integration</span>"
    ]
  },
  {
    "objectID": "week5.html#monte-carlo-integration-intro",
    "href": "week5.html#monte-carlo-integration-intro",
    "title": "5  Week 5 - Integration",
    "section": "5.2 Monte Carlo Integration Intro",
    "text": "5.2 Monte Carlo Integration Intro\n\n# define function\nf = lambda x, y: np.sqrt(x**2 + y**2)\n\n# define # of random points\nN = 10000000\n\n# randomly sample N points (x-coordinates and y-coordinates)\npts_x = np.random.random(size = N)\npts_y = np.random.random(size = N)\n\n# count how many points are inside of the circle\nnum_in = sum(f(pts_x, pts_y) &lt; 1)\n\n# calculate the ratio\nprint(4 * num_in/N)\n\n3.1413352\n\n\n\nsum(f(pts_x, pts_y) &lt; 1)\n\n7853338\n\n\nPractice\nWhat is the minimum number of points do you need to approximate \\(\\pi\\) to 6 decimal places?\nPractice\nCalculate the area under the curve for \\(f(x) = \\frac{1}{5} x^2 (5-x)\\) from \\([1,4]\\) using Monte Carlo integration.\n\n# define function\ng = lambda x, y: y - 1/5 * x**2 * (5-x)\n\n# define # of random points\nN = ...\n\n# randomly sample N points (x-coordinates and y-coordinates)\n# sample x points from [1,4]\npts_x = ...\n# sample y points from [0,3]\npts_y = ...\n\n# count how many points are on or below g(x)\nnum_in = ...\n# calculate the area of the bounding box/region\narea_of_rect = ...\n\n# calculate the ratio\nprint(area_of_rect * num_in/N)\n\n\n---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[9], line 19\n     16 area_of_rect = ...\n     18 # calculate the ratio\n---&gt; 19 print(area_of_rect * num_in/N)\n\nTypeError: unsupported operand type(s) for *: 'ellipsis' and 'ellipsis'\n\n\n\n\n#g(pts_x, pts_y)\n\n\nimport matplotlib.pyplot as plt\nplt.plot(pts_x,pts_y, 'o')\nplt.plot(pts_x, 1/5 * pts_x**2 * (5-pts_x), 'o')",
    "crumbs": [
      "Module 2 - Numerical Calculus",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Week 5 - Integration</span>"
    ]
  },
  {
    "objectID": "week5.html#using-numpy-and-scipy",
    "href": "week5.html#using-numpy-and-scipy",
    "title": "5  Week 5 - Integration",
    "section": "5.3 Using Numpy and Scipy",
    "text": "5.3 Using Numpy and Scipy\n\n5.3.1 Differentiation\nThere are two main tools built into the numpy and scipy libraries that do numerical differentiation. In numpy there is the np.diff() command. In scipy there is the scipy.misc.derivative() command.\n\n# ex 1\nmyList = np.arange(0,10)\nprint(myList)\nprint( np.diff(myList) )\n\n\n# ex 2\nmyList = np.linspace(0,1,6)\nprint(myList)\nprint( np.diff(myList) )\n\n\n# ex 3\nx = np.linspace(0,1,6)\ndx = x[1]-x[0]\ny = x**2\ndy = 2*x\nprint(\"function values: \\n\",y)\nprint(\"exact values of derivative: \\n\",dy)\nprint(\"values from np.diff(): \\n\",np.diff(y))\nprint(\"values from np.diff()/dx: \\n\",np.diff(y) / dx )\n\nQ: Why does the np.diff() command produce a list that is one element shorter than the original list?\n\n# what does this code do?\nx = np.linspace(0,1,6)\ndx = x[1]-x[0]\ny = x**2\nprint( np.diff(y,2) / dx**2 )\n\nNext we look into the scipy.misc.derivative() command from the scipy library. This will be another way to calculate the derivative of a function. One advantage will be that you can just send in a Python function (or a lambda function) without actually computing the lists of values. Examine the following Python code and fully describe what it does\n\nf = lambda x: x**2\nx = np.linspace(1,5,5)\ndf = scipy.misc.derivative(f,x,dx = 1e-10)\nprint(df)\n\n\nf = lambda x: x**2\ndf = scipy.misc.derivative(f,1,dx = 1e-10) # derivative at x=1\nprint(df)\n\n\n\n5.3.2 Integration\nIn numpy there is a nice tool called np.trapz() that implements the trapezoidal rule. In the following problem you will find several examples of the np.trapz() command. Use these examples to determine how the command works to integrate functions.\nLet’s approximate\n\\[\n\\int^2_{-2} x^2\\;dx\n\\]\n\nx = np.linspace(-2,2,100)\ndx = x[1]-x[0]\ny = x**2\nprint(\"Approximate integral is \",np.trapz(y)*dx)\n\nQ: What is the actual value?\nPractice\nPick a function and an interval for which you know the exact definite integral. Demonstrate how to use np.trapz() on your definite integral.\nIn the scipy library there is a more general tool called scipy.integrate.quad(). The term “quad” is short for “quadrature.” In numerical analysis literature rules like Simpson’s rule are called quadrature rules for integration. The function scipy.integrate.quad() accepts a Python function (or a lambda function) and the bounds of the definite integral. It outputs an approximation of the integral along with an approximation of the error in the integral calculation. See the Python code below.\n\nf = lambda x: x**2\nI = scipy.integrate.quad(f,-2,2)\nprint(I)",
    "crumbs": [
      "Module 2 - Numerical Calculus",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Week 5 - Integration</span>"
    ]
  },
  {
    "objectID": "week5.html#d-optimization",
    "href": "week5.html#d-optimization",
    "title": "5  Week 5 - Integration",
    "section": "5.4 1-D Optimization",
    "text": "5.4 1-D Optimization\nPractice\nGiven this box, we want to determine the value of \\(x\\) such that the volume of this box is maximized. How do we proceed?\n\nPractice\nIf you were blind folded and standing on a crater on the moon could you find the lowest point? How would you do it? Remember that you can hop as far as you like … because gravity … but sometimes that’s not a great thing because you could hop too far.",
    "crumbs": [
      "Module 2 - Numerical Calculus",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Week 5 - Integration</span>"
    ]
  },
  {
    "objectID": "module_three.html",
    "href": "module_three.html",
    "title": "Module 3 - Ordinary Differential Equations",
    "section": "",
    "text": "… to be added :]",
    "crumbs": [
      "Module 3 - Ordinary Differential Equations"
    ]
  },
  {
    "objectID": "week6.html",
    "href": "week6.html",
    "title": "6  MATH 291T - Week 6 Participation",
    "section": "",
    "text": "6.1 Intro to ODEs\nName: [Type Your Name Here]\nTo begin all assignments (whether participation or homework), please save a copy of this notebook to your Google Drive by clicking File -&gt; Save a copy in Drive\nPractice\nDescribe the plot of the function that would model the following scenario,\nA drug is eliminated from the body via natural metabolism. Assume that there is some initial amount of drug in the body. What does the function modeling the amount of drug in the system look like over time?\nPractice\nConsider the differential equation \\(x' = 3x\\) with an initial condition \\(x(0)=4.\\) Which of the following functions is a solution to this differential equation, and what is the value of the constant in the function?\nFor the one that is the solution, please type your solution below.",
    "crumbs": [
      "Module 3 - Ordinary Differential Equations",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>MATH 291T - Week 6 Participation</span>"
    ]
  },
  {
    "objectID": "week6.html#intro-to-odes",
    "href": "week6.html#intro-to-odes",
    "title": "6  MATH 291T - Week 6 Participation",
    "section": "",
    "text": "\\(x(t) = C \\sin(3t)\\)\n\\(x(t) = C e^{3t}\\)\n$x(t) = C t^3 $\n\\(x(t) = \\sin(3t) + C\\)\n\\(x(t) = e^{3t} + C\\)",
    "crumbs": [
      "Module 3 - Ordinary Differential Equations",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>MATH 291T - Week 6 Participation</span>"
    ]
  },
  {
    "objectID": "week6.html#separation-of-variables",
    "href": "week6.html#separation-of-variables",
    "title": "6  MATH 291T - Week 6 Participation",
    "section": "6.2 Separation of Variables",
    "text": "6.2 Separation of Variables\nPractice\nSolve the differential equation \\(x' = 2x + 12\\) with \\(x(0)=2\\) using separation of variables.\nPlease type your answer below.\nSubstitute your solution into the differential equation and verify that it solves it.\nANS:\nPractice\nSolve the differential equation \\[\n\\frac{dx}{dt} = x \\sin(t)\n\\]\nwith \\(x(0) = 1\\) using separation of variables.\nPlease type your answer below. Substitute your solution into the differential equation and verify that it solves it.\nANS:",
    "crumbs": [
      "Module 3 - Ordinary Differential Equations",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>MATH 291T - Week 6 Participation</span>"
    ]
  },
  {
    "objectID": "week6.html#eulers-method",
    "href": "week6.html#eulers-method",
    "title": "6  MATH 291T - Week 6 Participation",
    "section": "6.3 Euler’s Method",
    "text": "6.3 Euler’s Method\nWe want to approximate a solution to \\(x'(t) = f(t,x(t))\\).\nRecall that \\[\nx'(t) = \\frac{x(t+h) - x(t)}{h} + \\mathcal{O}(h)\n\\]\nso the differential equation \\(x'(t) = f(x(t),t)\\) becomes\n\\[\n\\frac{x(t+h) - x(t)}{h} \\approx f(x(t),t).\n\\]\nRewriting as a difference equation, letting \\(x_{n+1} = x(t_n+h)\\) and \\(x_n = x(t_n)\\), we get\n\\[\nx_{n+1} = x_n + h f(x_n, t_n)\n\\]\nPractice\nConsider the differential equation \\(x' = 0.5x\\) with \\(x(0)=6\\).\nComplete the following table using Euler’s method, with \\(h=1\\).\nYou can either write code to do this or do it by hand.\n\n\n\nt\n0\n1\n2\n3\n4\n5\n6\n\n\n\n\nApproximation of x(t)\n6\n-\n-\n-\n-\n-\n-\n\n\n\n\n# if time permits, create a plot with your analytical\n# solution and the approximate solution\nimport numpy as np\nt = np.array([0,1,2,3,4,5,6])\napprox = [6, 9, 13.5, 20.25, 30.375, 45.5625, 68.34375]\n\nf = lambda x: 6 * np.exp(0.5*x)\nactual = f(t)\n\n\nimport matplotlib.pyplot as plt\nplt.plot(t,actual)\nplt.plot(t, approx, 'o')",
    "crumbs": [
      "Module 3 - Ordinary Differential Equations",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>MATH 291T - Week 6 Participation</span>"
    ]
  },
  {
    "objectID": "week7.html",
    "href": "week7.html",
    "title": "7  MATH 291T - Week 7 Participation",
    "section": "",
    "text": "7.1 Euler’s Method\nName: [Type Your Name Here]\nTo begin all assignments (whether participation or homework), please save a copy of this notebook to your Google Drive by clicking File -&gt; Save a copy in Drive\nThe notion of approximating solutions to differential equations is simple in principle:\nPractice\nConsider the differential equation \\(x' = 0.5x\\) with \\(x(0)=6\\).\nWrite a function that takes the following as input:\nand outputs:\nGraph your approximation with 3 different values of \\(h\\).\nIn this case, the analytical solution is\ndef euler(f,x0,t0,tmax,dt):\n  # write out the quantities needed (number of points, grid, solution)\n  # determine number of points needed, N\n\n  # define t based on N\n\n  # define x\n\n  # define x[0] to be the initial condition\n\n  # for loop to update the solution x(t) with Euler method\n  for n in range(len(t) - 1):\n\n  return t, x\nfp = lambda t, x: 0.5*x\nte, xe = euler(fp, x0=6, t0=0, tmax=10, dt=1e-3)\nte2, xe2 = euler(fp, x0=6, t0=0, tmax=10, dt=1)\n\n# now make some plots!\nf = lambda t, x: 6 * np.exp(0.5*x)\n#t_true = np.linspace(0,10,1000)\nf_true = f(0, te)\nfig = go.Figure()\nfig.add_trace(go.Scatter(x=te, y=xe, mode='markers', name=\"Euler dt=1e-02\"))\nfig.add_trace(go.Scatter(x=te2, y=xe2, mode='markers', name=\"Euler dt=1\"))\nfig.add_trace(go.Scatter(x=te, y=f_true, mode='markers', name=\"Analytical Sol.\"))\nfig.show()\nCalculate the point-wise error (i.e., the error at each point you are estimating the solution) and 1) find the maximum and 2) graph them.\nplt.plot(f_true-xe, 'o')",
    "crumbs": [
      "Module 3 - Ordinary Differential Equations",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>MATH 291T - Week 7 Participation</span>"
    ]
  },
  {
    "objectID": "week7.html#eulers-method",
    "href": "week7.html#eulers-method",
    "title": "7  MATH 291T - Week 7 Participation",
    "section": "",
    "text": "make a discrete approximation to the derivative and\nstep forward through time as a difference equation.\n\n\n\n\n\na function \\(f\\)\na step size \\(h\\)\nan initial condition\na start time\nan end time\n\n\n\nthe estimated solution using Euler’s method & the grid where solution is evaluated\n\n\n\nf = lambda x: 6 * np.exp(0.5*x)",
    "crumbs": [
      "Module 3 - Ordinary Differential Equations",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>MATH 291T - Week 7 Participation</span>"
    ]
  },
  {
    "objectID": "week7.html#midpoint-method",
    "href": "week7.html#midpoint-method",
    "title": "7  MATH 291T - Week 7 Participation",
    "section": "7.2 Midpoint Method",
    "text": "7.2 Midpoint Method\nNow we get to improve upon Euler’s method. There is a long history of wonderful improvements to the classic Euler’s method - some that work in special cases, some that resolve areas where the error is going to be high, and some that are great for general purpose numerical solutions to ODEs with relatively high accuracy. In this section we’ll make a simple modification to Euler’s method that has a surprisingly great payoff in the error rate.\nLet’s return to the simple differential equation\n\\[\nx'= - 0.5 x\n\\]\nwith \\(x(0)=6\\) that we saw before. Now we’ll propose a slightly different method for approximating the solution.\nAt \\(t=0\\), we know that \\(x(0)=6\\). If we use the slope at time \\(t=0\\) to step forward in time then we will get the Euler approximation of the solution. Consider this alternative approach:\n\nUse the slope at time \\(t=0\\) and move half a step forward.\nFind the slope at the half-way point\nThen use the slope from the half way point to go a full step forward from time \\(t=0\\).\n\nLet’s build this idea together:\n\nWhat is the slope at time \\(t=0\\)? \\(x'(0) = ?\\).\nUse this slope to step a half step forward and find the \\(x\\) value: \\(x(0.5) \\approx ?\\)\nNow use the differential equation to find the slope at time\n\\(t=0.5\\). \\(x'(0.5) = ?\\).\nNow take your answer from the previous step, and go one full step forward from time \\(t=0\\). What \\(x\\) value do you end up with?\nRepeat the process outlined in part (a) to approximate the solution to the differential equation at times \\(t=2, 3, \\ldots\\) 6. Plot the analytical solution, the approximation using Euler’s method, and this new method.\n\nPractice\nComplete the code below to implement the midpoint method in one dimension.\nThen, apply it to the previous problem (\\(x' = -0.5x\\)).\n\ndef midpoint1d(f,x0,t0,tmax,dt):\n    N = int(np.floor((tmax-t0)/dt) +1)\n    t = np.linspace(t0, tmax, N)# build the times\n    x = np.zeros(len(t))# build an array for the x values\n    x[0] = x0# build the initial condition\n    # On the next line: be careful about how far you're looping\n    for n in range( ... ):\n        # The interesting part of the code goes here.\n    return t, x\n\n\nf2 = lambda t, x: 3*x + t\nprint(midpoint1d(f2, x0 = 4, t0 = 0, tmax = 1, dt = 1))\n\n(array([0., 1.]), array([ 4. , 34.5]))\n\n\n\nf1 = lambda t, x: 0.2*x + 1\nprint(midpoint1d(f1, x0 = 0, t0 = 0, tmax = 1, dt = 1))\n\n(array([0., 1.]), array([0. , 1.1]))\n\n\n\n# write some code below to make some plots\nfig = go.Figure()\n#fig.add_trace(go.Scatter(x=, y=, mode='markers', name=\"Midpoint Method\"))\n#fig.add_trace(go.Scatter(x=, y=, mode='markers', name=\"Analytical Sol.\"))\n\nThe goal in building the midpoint method was to hopefully capture some of the upcoming curvature in the solution before we overshot it.\nPractice\nConsider the differential equation \\(x' = -1/3x + \\sin(t)\\) with initial condition \\(x(0)=1\\) on the domain \\(t\\in[0,4]\\). First get a numerical solution with Euler’s method using \\(\\Delta t = 0.1\\). Then get a numerical solution with the midpoint method using the same value for \\(\\Delta t\\). Plot the two solutions on top of each other along with the exact solution\n\\[\nx(t) = 1/10 \\left(19 e^{-t/3} + 3 \\sin(t) - 9 \\cos(t) \\right)\n\\]\nWhat do you observe? What do you observe if you make \\(\\Delta t\\) a bit larger (like 0.2 or 0.3)? What do you observe if you make \\(\\Delta t\\) very very small (like 0.001 or 0.0001)?\n\n# define the right-hand side (rhs)\nfp = lambda t, x: -1/3*x + np.sin(t)\n# set dt\ndt1 = 0.1\n# solve with Euler's method\nte, xe = ...\n# solve with Midpoint method\ntm, xm = ...\n\n# define the analytical solution\nf = lambda t, x: 1/10 *(19*np.exp(-t/3) + 3*np.sin(t) - 9*np.cos(t))\n# evaluate the solution at the grid above\nftrue = f(te, 0)\n\n\n# add plots and analysis :]",
    "crumbs": [
      "Module 3 - Ordinary Differential Equations",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>MATH 291T - Week 7 Participation</span>"
    ]
  },
  {
    "objectID": "week7.html#interactive-odes",
    "href": "week7.html#interactive-odes",
    "title": "7  MATH 291T - Week 7 Participation",
    "section": "7.3 Interactive ODEs",
    "text": "7.3 Interactive ODEs\n\nf = lambda t, x: -(1/3.0)*x + np.sin(t)\nt0 = 0\n\n\ndef eulerAnimator(x0,tmax,dt):\n    # call on the euler function to build the solution\n    t, x = euler(f,x0,t0,tmax,dt)\n    plt.plot(t, x, 'b-') # plot the solution\n    plt.xlim(0,30)\n    plt.ylim( np.min(x)-1, np.max(x)+1)\n    plt.grid()\n    plt.show()\n\n\ninteractive_plot = interactive(eulerAnimator,\n                               x0=(-2, 5, 0.5),\n                               tmax=(1, 30, 0.1),\n                               dt=(0.01, 0.75, 0.005))\ninteractive_plot\n\n\n\n\nPractice\nModify the previous exercise to use a different numerical solver (e.g. the midpoint method) instead of Euler’s method.\nIF Time permits",
    "crumbs": [
      "Module 3 - Ordinary Differential Equations",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>MATH 291T - Week 7 Participation</span>"
    ]
  },
  {
    "objectID": "module_four.html",
    "href": "module_four.html",
    "title": "Module 4 - Partial Differential Equations",
    "section": "",
    "text": "… to be added :]",
    "crumbs": [
      "Module 4 - Partial Differential Equations"
    ]
  }
]